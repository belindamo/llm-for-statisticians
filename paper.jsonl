{"id":"nakada2025theoretical","title":"A Theoretical Framework for Prompt Engineering: Approximating Smooth Functions with Transformer Prompts","authors":"Ryumei Nakada, Wenlong Ji, Tianxi Cai, James Zou, Linjun Zhang","journal":"arXiv preprint","year":"2025","doi":"arXiv:2503.20561","url":"https://arxiv.org/abs/2503.20561","keyAssumptions":"Prompts can configure transformer internal computations dynamically; Structured prompts enable arbitrary precision function approximation","keyHypotheses":"Transformers with designed prompts act as configurable computational systems; Virtual network emulation during inference is achievable","strengths":"Foundational theoretical framework; Rigorous mathematical treatment; Direct relevance to function approximation","weaknesses":"Limited empirical validation; Complexity of practical implementation","citation":"Nakada, R., et al. (2025). A Theoretical Framework for Prompt Engineering. arXiv:2503.20561","notes":"Core theoretical foundation for our research direction","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"murthy2025promptomatix","title":"Promptomatix: An Automatic Prompt Optimization Framework for Large Language Models","authors":"Rithesh Murthy, Ming Zhu, Liangwei Yang, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2507.14241","url":"https://arxiv.org/abs/2507.14241","keyAssumptions":"Manual expertise not required for effective prompts; Automated methods can match human performance","keyHypotheses":"Natural language descriptions can be automatically transformed into high-quality prompts","strengths":"Practical automated framework; Reduces computational overhead; Accessible to non-experts","weaknesses":"Limited to specific task categories; May not capture domain-specific nuances","citation":"Murthy, R., et al. (2025). Promptomatix: An Automatic Prompt Optimization Framework. arXiv:2507.14241","notes":"Automation reduces barrier to prompt engineering","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"zhu2025mepo","title":"Rethinking Prompt Optimizers: From Prompt Merits to Optimization","authors":"Zixiao Zhu, Hanzhang Zhou, Zijian Feng, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2505.09930","url":"https://arxiv.org/abs/2505.09930","keyAssumptions":"Model-agnostic merits exist for prompt quality; Interpretable optimization is preferable","keyHypotheses":"Merit-guided optimization generalizes across model types; Local deployment addresses privacy concerns","strengths":"Model-agnostic approach; Interpretable optimization; Privacy-preserving","weaknesses":"Limited evaluation across diverse architectures; Merit identification complexity","citation":"Zhu, Z., et al. (2025). Rethinking Prompt Optimizers. arXiv:2505.09930","notes":"Addresses compatibility issues across model scales","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"liu2025cfpo","title":"Beyond Prompt Content: Enhancing LLM Performance via Content-Format Integrated Prompt Optimization","authors":"Yuanye Liu, Jiahang Xu, Li Lyna Zhang, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2502.04295","url":"https://arxiv.org/abs/2502.04295","keyAssumptions":"Content and format should be jointly optimized; Format plays critical role in effectiveness","keyHypotheses":"Integrated content-format optimization outperforms content-only approaches","strengths":"Comprehensive optimization approach; Measurable improvements; Model-agnostic","weaknesses":"Increased optimization complexity; Limited format exploration strategies","citation":"Liu, Y., et al. (2025). Beyond Prompt Content. arXiv:2502.04295","notes":"Highlights overlooked dimension of prompt formatting","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"genewein2025understanding","title":"Understanding Prompt Tuning and In-Context Learning via Meta-Learning","authors":"Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2505.17010","url":"https://arxiv.org/abs/2505.17010","keyAssumptions":"Optimal prompting has formal limitations; Meta-trained networks behave as Bayesian predictors","keyHypotheses":"Bayesian view explains prompting effectiveness; Formal criteria determine prompting applicability","strengths":"Theoretical foundation; Bayesian framework; Educational experiments","weaknesses":"Limited practical guidelines; Complex theoretical concepts","citation":"Genewein, T., et al. (2025). Understanding Prompt Tuning and In-Context Learning. arXiv:2505.17010","notes":"Provides theoretical understanding of prompting limitations","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"lampinen2024broader","title":"The broader spectrum of in-context learning","authors":"Andrew Kyle Lampinen, Stephanie C. Y. Chan, Aaditya K. Singh, Murray Shanahan","journal":"arXiv preprint","year":"2024","doi":"arXiv:2412.03782","url":"https://arxiv.org/abs/2412.03782","keyAssumptions":"In-context learning extends beyond supervised scenarios; Context-loss relationship defines ICL","keyHypotheses":"Unified framework can explain diverse in-context capabilities","strengths":"Unifying theoretical perspective; Broad applicability; Connects to meta-learning","weaknesses":"Abstract framework; Limited concrete applications","citation":"Lampinen, A.K., et al. (2024). The broader spectrum of in-context learning. arXiv:2412.03782","notes":"Expands understanding of in-context learning scope","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"xu2025reason","title":"Reason from Future: Reverse Thought Chain Enhances LLM Reasoning","authors":"Yinlong Xu, Yanzhao Zheng, Shuoshuo Sun, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2506.03673","url":"https://arxiv.org/abs/2506.03673","keyAssumptions":"Sequential reasoning is suboptimal; Global perspective improves reasoning","keyHypotheses":"Bidirectional reasoning outperforms forward-only approaches","strengths":"Novel reasoning paradigm; Reduced search space; Higher accuracy","weaknesses":"Increased complexity; Limited evaluation domains","citation":"Xu, Y., et al. (2025). Reason from Future: Reverse Thought Chain. arXiv:2506.03673","notes":"Challenges sequential reasoning assumptions","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"xu2025chain","title":"Chain of Draft: Thinking Faster by Writing Less","authors":"Silei Xu, Wenhao Xie, Lingxiao Zhao, Pengcheng He","journal":"arXiv preprint","year":"2025","doi":"arXiv:2502.18600","url":"https://arxiv.org/abs/2502.18600","keyAssumptions":"Verbose reasoning is not necessary; Concise drafts can be equally effective","keyHypotheses":"Minimalistic reasoning matches verbose approaches with reduced tokens","strengths":"Significant token reduction; Maintained accuracy; Cost efficiency","weaknesses":"Limited to specific reasoning types; Conciseness-accuracy tradeoff","citation":"Xu, S., et al. (2025). Chain of Draft: Thinking Faster by Writing Less. arXiv:2502.18600","notes":"Efficiency breakthrough in reasoning approaches","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"abdaljalil2025theorem","title":"Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models","authors":"Samir Abdaljalil, Hasan Kurban, Khalid Qaraqe, Erchin Serpedin","journal":"arXiv preprint","year":"2025","doi":"arXiv:2506.07106","url":"https://arxiv.org/abs/2506.07106","keyAssumptions":"Multi-agent reasoning outperforms single-agent; Different reasoning modes complement each other","keyHypotheses":"Collaborative reasoning with formal graphs improves logical consistency","strengths":"Multi-modal reasoning; Formal graph structure; Interpretable processes","weaknesses":"Computational complexity; Implementation challenges","citation":"Abdaljalil, S., et al. (2025). Theorem-of-Thought. arXiv:2506.07106","notes":"Advanced multi-agent reasoning framework","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"xu2025softcot","title":"SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs","authors":"Yige Xu, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2502.12134","url":"https://arxiv.org/abs/2502.12134","keyAssumptions":"Continuous reasoning outperforms discrete tokens; Core LLM architecture should remain unchanged","keyHypotheses":"Soft thought tokens enable continuous reasoning without full model modification","strengths":"Parameter-efficient; Maintains LLM compatibility; Enhanced reasoning","weaknesses":"Requires additional assistant model; Limited evaluation scope","citation":"Xu, Y., et al. (2025). SoftCoT: Soft Chain-of-Thought. arXiv:2502.12134","notes":"Continuous reasoning approach","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"muppidi2025leveraging","title":"Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs","authors":"Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay","journal":"arXiv preprint","year":"2025","doi":"arXiv:2506.05629","url":"https://arxiv.org/abs/2506.05629","keyAssumptions":"Input-dependent prompts outperform static ones; Self-attention improves prompt effectiveness","keyHypotheses":"Dynamic prompt generation based on input characteristics improves adaptability","strengths":"Dynamic adaptation; Improved domain transfer; Parameter efficiency","weaknesses":"Increased computational overhead; Limited architectural diversity","citation":"Muppidi, A., et al. (2025). Leveraging Self-Attention for Input-Dependent Soft Prompting. arXiv:2506.05629","notes":"Dynamic soft prompting innovation","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"samuel2025cie","title":"CIE: Controlling Language Model Text Generations Using Continuous Signals","authors":"Vinay Samuel, Harshita Diddee, Yiming Zhang, Daphne Ippolito","journal":"arXiv preprint","year":"2025","doi":"arXiv:2505.13448","url":"https://arxiv.org/abs/2505.13448","keyAssumptions":"Continuous control outperforms discrete alternatives; Fine-grained control is achievable","keyHypotheses":"Vector interpolation between embeddings enables precise property control","strengths":"Fine-grained control; Reliable property manipulation; Continuous spectrum control","weaknesses":"Limited to specific properties; Requires fine-tuning","citation":"Samuel, V., et al. (2025). CIE: Controlling Language Model Text Generations. arXiv:2505.13448","notes":"Continuous control paradigm for generation properties","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"sahoo2024systematic","title":"A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications","authors":"Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, et al.","journal":"arXiv preprint","year":"2024","doi":"arXiv:2402.07927","url":"https://arxiv.org/abs/2402.07927","keyAssumptions":"Systematic categorization aids understanding; Techniques vary significantly across applications","keyHypotheses":"Comprehensive survey can identify patterns and gaps in prompt engineering","strengths":"Comprehensive coverage; Systematic organization; Identifies research gaps","weaknesses":"Limited depth on individual techniques; Rapid field evolution","citation":"Sahoo, P., et al. (2024). A Systematic Survey of Prompt Engineering. arXiv:2402.07927","notes":"Comprehensive methodological overview","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"li2025survey","title":"A Survey of Automatic Prompt Engineering: An Optimization Perspective","authors":"Wenwu Li, Xiangfeng Wang, Wenhao Li, Bo Jin","journal":"arXiv preprint","year":"2025","doi":"arXiv:2502.11560","url":"https://arxiv.org/abs/2502.11560","keyAssumptions":"Optimization perspective unifies diverse methods; Automated methods are increasingly important","keyHypotheses":"Unified optimization framework can organize and advance automated prompt engineering","strengths":"Unified theoretical lens; Cross-modal coverage; Optimization focus","weaknesses":"High-level abstraction; Limited practical guidelines","citation":"Li, W., et al. (2025). A Survey of Automatic Prompt Engineering. arXiv:2502.11560","notes":"Optimization-theoretic survey of automated methods","addedDate":"2025-08-26T01:05:23.493Z"}
{"id":"long2025what","title":"What Makes a Good Natural Language Prompt?","authors":"Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, et al.","journal":"arXiv preprint","year":"2025","doi":"arXiv:2506.06950","url":"https://arxiv.org/abs/2506.06950","keyAssumptions":"Prompt quality can be systematically evaluated; Properties correlate with effectiveness","keyHypotheses":"Property-centric framework enables better prompt evaluation and optimization","strengths":"Systematic property framework; Meta-analysis approach; Practical recommendations","weaknesses":"Limited validation across models; Property interaction complexity","citation":"Long, D.X., et al. (2025). What Makes a Good Natural Language Prompt? arXiv:2506.06950","notes":"Property-centric prompt evaluation framework","addedDate":"2025-08-26T01:05:23.493Z"}